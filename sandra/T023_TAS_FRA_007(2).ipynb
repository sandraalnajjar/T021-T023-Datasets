{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Unit: 10^9 tonne-km / yr, Unit Factor: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magli\\AppData\\Local\\Temp\\ipykernel_8272\\4215842456.py:255: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={column_names_lower[index]: expected_column}, inplace=True)\n",
      "C:\\Users\\magli\\AppData\\Local\\Temp\\ipykernel_8272\\4215842456.py:285: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={column_names_lower[index]: expected_column}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os#reading&write\n",
    "import os.path# used to perform operations related to files and paths\n",
    "#(checking the existence of a file, obtaining information about files, and constructing or examining paths).\n",
    "import yaml # YAML is a human-readable data\n",
    "from yaml.loader import SafeLoader#used for safely loading YAML document\n",
    "#Safeloader:avoiding the execution of arbitrary code.\n",
    "import pycountry#it is a useful for dealing with country & currency information in a standardized way based on ISO codes.\n",
    "import math\n",
    "\n",
    "class AtoWorkbook:\n",
    "            \n",
    "    # Function that loads rule book\n",
    "    def load_rule_book(self, file_name: str):\n",
    "        with open(file_name) as f:\n",
    "            SOURCES = yaml.load(f, Loader=SafeLoader)\n",
    "        return SOURCES\n",
    "\n",
    "    # # Function that loads yaml file containing mapping of ISO_Code with Regions\n",
    "    def populate_regions(self, file_name: str):\n",
    "        REGION = {}\n",
    "        # Populate the map from the regions.yaml file\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            yaml_data = yaml.load(file, Loader=SafeLoader)\n",
    "            for region_name, info in yaml_data.items():\n",
    "                if isinstance(info, dict):  # Check if info is a dictionary\n",
    "                    REGION.update({c: region_name for c in info.get(\"countries\", [])})\n",
    "        return REGION\n",
    "\n",
    "       # Function that extracts Country and Region using ISO_Code\n",
    "        # ISO code of the country for which we want to extract information\n",
    "        #regions dictionary containing mapping of ISO codes with regions.\n",
    "    def extract_country_region(self, iso_code, regions):\n",
    "        country_info = regions.get(iso_code, {})\n",
    "        country_name = country_info.get('country', 'Unknown Country')\n",
    "        region_name = country_info.get('region', 'Unknown Region')\n",
    "        return country_name, region_name\n",
    "    \n",
    "    # # Function that mapps ISO_Code to Country and Region\n",
    "    def country_region_mapping(self, economy_code, regions):\n",
    "        COUNTRY = dict()  # Initialize an empty dictionary to store country information\n",
    "        region_country_list = []  # Initialize an empty list to store country and region names\n",
    "\n",
    "\n",
    "        try: # Try to get country information using the provided ISO code\n",
    "            country = pycountry.countries.get(alpha_3=economy_code)\n",
    "\n",
    "            if country: # If country information is found\n",
    "                country_name = country.name\n",
    "                region_country_list = [country_name, regions.get(economy_code, 'Unknown Region')]\n",
    "                COUNTRY.update({economy_code: region_country_list})\n",
    "            else:\n",
    "                # Handle the case where the country is not found\n",
    "                country_name = 'Unknown Country'\n",
    "                region_name = 'Unknown Region'\n",
    "                region_country_list = [country_name, region_name]\n",
    "                COUNTRY.update({economy_code: region_country_list})\n",
    "        except LookupError as e: # Handle lookup errors, such as an invalid ISO code\n",
    "            print(f\"LookupError: {e}\")\n",
    "            print(f\"Economy Code: {economy_code}\")\n",
    "        \n",
    "        return COUNTRY\n",
    "\n",
    "\n",
    "      \n",
    "    # Function that returns ruleID, indicator_name and dictionary\n",
    "            #rule_book:dictionary containing rule information.\n",
    "    def get_rule_id(self, rule_book:dict):\n",
    "        rule_id = \"Txxx\"#default value \n",
    "        valid_id_found = False# boolean variable to track whether a valid rule ID is found.\n",
    "\n",
    "        for key, value in rule_book.items():        \n",
    "            for new_key, new_val in value.items():\n",
    "                if new_key == \"name\":\n",
    "                    indicator_name = new_val                \n",
    "                    dataset_name_split = new_val.split('-')\n",
    "                    list_length = len(dataset_name_split)\n",
    "                    for index in range(list_length):\n",
    "                        if \"Aviation(Domestic)\" in dataset_name_split[index]:\n",
    "                            valid_id_found = True\n",
    "                            rule_id = key\n",
    "                            break    \n",
    "                        else:\n",
    "                            valid_id_found = False\n",
    "\n",
    "            if valid_id_found:            \n",
    "               break\n",
    "\n",
    "        return rule_id, value, indicator_name\n",
    "    \n",
    "    # # Function that returns Vehicle Type\n",
    "\n",
    "    def get_vehicle_type(self, mode: str, item_value: dict, dataset_name: str):\n",
    "        \"\"\"Determine 'Vehicle type' from 'mode' and 'indicator'\"\"\"\n",
    "\n",
    "        splited_indicator_name = dataset_name.split('-')\n",
    "        first_indicator_word = splited_indicator_name[0]\n",
    "        mode_indicator = mode + \" \" +  first_indicator_word\n",
    "        mode_indicator = mode_indicator.rstrip() #string method in Python that returns a copy of the string with trailing whitespaces removed.          \n",
    "        VehicleType = \"All\"\n",
    "        vehicle_type_found = False\n",
    "\n",
    "        # Check if \"VehicleType\" key is present in item_value\n",
    "        if \"VehicleType\" in item_value:\n",
    "            new_val = item_value[\"VehicleType\"]\n",
    "\n",
    "            # Check if new_val is a dictionary\n",
    "            if isinstance(new_val, dict):#is a built-in Python function used to check if an object is an instance of a particular class or type.\n",
    "                for key1, value1 in new_val.items():\n",
    "                    if mode_indicator in key1:\n",
    "                        VehicleType = \"All\"                 \n",
    "                        vehicle_type_found = True\n",
    "                        break\n",
    "\n",
    "        if vehicle_type_found:\n",
    "            return VehicleType\n",
    "        else:\n",
    "            # If \"VehicleType\" key is not present or new_val is not a dictionary\n",
    "            return \"All\"\n",
    "\n",
    "\n",
    "    def get_variable_type(self, service_name: str, indicator_name: str):\n",
    "        \"\"\"Determine 'variable' using Service name.\n",
    "\n",
    "        The rules implemented are:\n",
    "        ============================================= ===== ============\n",
    "        Variable types                                 \n",
    "        ============================================= ===== ============\n",
    "        Variable: \"Freight Activity\"\n",
    "        ============================================= ===== ============\n",
    "        \"\"\"\n",
    "        variable =\"NA\"  # Initialize variable to None\n",
    "\n",
    "        # Check if the service_name contains \"Freight\" and indicator_name contains \"Aviation(Domestic)\"\n",
    "        if \"Freight\" in service_name and \"Freight Transport - Tonne-km for Aviation (Domestic)\" in indicator_name:\n",
    "            variable = \"Freight Activity\"\n",
    "\n",
    "        return variable\n",
    "\n",
    "\n",
    "\n",
    "    def get_unit_and_unit_factor(self, item_value: dict, unit_name: str):\n",
    "        \"\"\"Determine 'expected unit' and 'unit factor' from 'Unit'.\n",
    "\n",
    "        The rules implemented are:\n",
    "\n",
    "        ============================================= ===== ============\n",
    "        Unit                                    \n",
    "        ============================================= ===== ============\n",
    "        The unit is changed from Million tonne kilometers to 10^9  tonne-km / yr.\n",
    "        # Unit: \"Million tonne kilometers to 10^9 tonne-km / yr\"\n",
    "        ============================================= ===== ============\n",
    "        \"\"\"\n",
    "        expected_unit = \"10^9 tonne-km / yr\"\n",
    "        unit_factor = 1000 #default factor\n",
    "        unit_found = False\n",
    "\n",
    "        for key, value in item_value.items():\n",
    "            if key == \"Unit\":\n",
    "                for sub_key, sub_value in value.items():\n",
    "                    if unit_name in sub_value:\n",
    "                        expected_unit = \"10^9 tonne-km / yr\"\n",
    "                        unit_factor = 1000\n",
    "                        unit_found = True\n",
    "                        break\n",
    "\n",
    "        if unit_found:\n",
    "            print(f\"Expected Unit: {expected_unit}, Unit Factor: {unit_factor}\")\n",
    "        else:\n",
    "            print(f\"Unit {unit_name} not found in the rule book.\")\n",
    "\n",
    "        return expected_unit, unit_factor\n",
    "    \n",
    "        #Function that extracts upper part of the dataframe\n",
    "    #And returns [mode_value, source_value, service_value, unit_value, indicator_value, sheet_name]\n",
    "    def extract_upper_part_one(self, df_upper: pd.DataFrame):\n",
    "        column_names = list(df_upper.columns.values) # Get the column names of the DataFrame's upper part\n",
    "\n",
    "        upper_part_attributes = []#empty list to store upper part attributes\n",
    "\n",
    "        # Accessing the \"Mode\" attribute\n",
    "        mode_value = \"Aviation (Domestic)\"\n",
    "        upper_part_attributes.append(mode_value)\n",
    "\n",
    "        source_long_name = \"Asian Transport Outlook National Database\"\n",
    "        if column_names[1] == source_long_name:\n",
    "            source_short_name = \"ATO\"\n",
    "        # Accessing the \"Source:\" attribute\n",
    "        source_value = source_short_name + \"2023 \" + df_upper.loc[1, column_names[1]]\n",
    "        upper_part_attributes.append(source_value)    \n",
    "        \n",
    "        # Accessing the \"Sector or Service\" attribute\n",
    "        service_value = df_upper.loc[5, column_names[1]]\n",
    "        upper_part_attributes.append(service_value)\n",
    "\n",
    "        # Accessing the \"Unit\" attribute\n",
    "        unit_value = df_upper.loc[6, column_names[1]]\n",
    "        upper_part_attributes.append(unit_value)\n",
    "\n",
    "        # Accessing the \"Indicator\" attribute\n",
    "        indicator_value = df_upper.loc[0, column_names[1]]\n",
    "        upper_part_attributes.append(indicator_value)\n",
    "\n",
    "        # Accessing the \"Indicator ATO Code:\" attribute\n",
    "        sheet_name = df_upper.loc[1, column_names[1]]\n",
    "        upper_part_attributes.append(sheet_name)\n",
    "\n",
    "        return upper_part_attributes \n",
    "    \n",
    "        # Function that extracts remaing upper part of the dataframe\n",
    "    # And returns [vehicle_type, variable_type, unit, unit_factor, rule_id]\n",
    "    def extract_upper_part_two(self, upper_part_attributes: list, rule_book: dict):\n",
    "        #[mode_value, source_value, service_value, unit_value, indicator_value, sheet_name]\n",
    "        remaining_part_attributes = []\n",
    "\n",
    "        rule_id, item_value, indicator_name = self.get_rule_id(rule_book)\n",
    "\n",
    "        vehicleType = self.get_vehicle_type(upper_part_attributes[0], item_value, indicator_name)\n",
    "        \n",
    "        unit, unit_factor = self.get_unit_and_unit_factor(item_value, upper_part_attributes[3])\n",
    "\n",
    "        variable_type = self.get_variable_type(upper_part_attributes[2], upper_part_attributes[4])\n",
    "\n",
    "        remaining_part_attributes.append(vehicleType)    \n",
    "        remaining_part_attributes.append(variable_type)\n",
    "        remaining_part_attributes.append(unit)\n",
    "        remaining_part_attributes.append(unit_factor)\n",
    "        remaining_part_attributes.append(rule_id)\n",
    "\n",
    "        return remaining_part_attributes\n",
    "    \n",
    "    # Function that updates correct columns in the lower dataframe\n",
    "    def process_lower_part(self, df: pd.DataFrame):\n",
    "        # Get the column names of the lower part of the DataFrame\n",
    "        column_names_lower = list(df.columns.values)\n",
    "        \n",
    "        # Get the total number of columns\n",
    "        column_length = len(column_names_lower)\n",
    "        \n",
    "        # Initialize counters and lists\n",
    "        valid_column_length = 0\n",
    "        updated_column_names = []\n",
    "\n",
    "        # Loop through each column in the lower part\n",
    "        for index in range(column_length):\n",
    "            # Remove extra white space from the end of a string\n",
    "            column_names_lower[index].rstrip()\n",
    "\n",
    "            # For the first two columns (Economy Code and Economy Name)\n",
    "            if index < 2:\n",
    "                # Get the expected column name from row 13\n",
    "                expected_column = df.loc[13, column_names_lower[index]]\n",
    "\n",
    "                # Replace column names of the DataFrame with the correct column name\n",
    "                df.rename(columns={column_names_lower[index]: expected_column}, inplace=True)\n",
    "                \n",
    "                # Append the updated column name to the list\n",
    "                updated_column_names.append(expected_column)\n",
    "\n",
    "            # For columns from 1990 up to 2022\n",
    "            else:\n",
    "                # Get the expected column name from row 13\n",
    "                expected_column = df.loc[13, column_names_lower[index]]\n",
    "                \n",
    "                # Check if the expected column name is a string\n",
    "                same_type = isinstance(expected_column, str)\n",
    "\n",
    "                # If the column value is not a string\n",
    "                if not same_type:\n",
    "                    # Remove decimal numbers\n",
    "                    expected_column = math.trunc(expected_column)\n",
    "                    \n",
    "                    # Convert the integer into a string\n",
    "                    expected_column = str(expected_column)\n",
    "\n",
    "                try:\n",
    "                    # Try to convert the expected column name into an integer\n",
    "                    valid_column = int(expected_column)\n",
    "                    \n",
    "                    # Check if the conversion is successful (it's an integer)\n",
    "                    int_type = isinstance(valid_column, int)\n",
    "                    \n",
    "                    if int_type:\n",
    "                        # Replace column names of the DataFrame with the correct column name\n",
    "                        df.rename(columns={column_names_lower[index]: expected_column}, inplace=True)\n",
    "                        \n",
    "                        # Append the updated column name to the list\n",
    "                        updated_column_names.append(expected_column)\n",
    "                except ValueError:\n",
    "                    # Handle the case where the column name cannot be converted to an integer\n",
    "                    print(\"Invalid column name for: \" + expected_column)\n",
    "\n",
    "        # Create a new DataFrame with updated column names and drop the row 13\n",
    "        df_lower_updated = df[updated_column_names].copy()\n",
    "        df_lower_new = df_lower_updated.drop([13])\n",
    "\n",
    "        return df_lower_new, updated_column_names\n",
    "\n",
    "\n",
    "    def update_master_data(self, df_out_put: pd.DataFrame, df: pd.DataFrame, column_list_names,\n",
    "                        upper_attributes, remaining_attributes, regions):\n",
    "        #[mode_value, source_value, service_value, unit_value, indicator_value, sheet_name]\n",
    "        #[vehicle_type, variable_type, unit, unit_factor, rule_id]\n",
    "        for index, row in df.iterrows():\n",
    "            # Skip rows with missing or invalid 'Economy Code'\n",
    "            if pd.notna(row['Economy Code']):\n",
    "                country_new = self.country_region_mapping(row['Economy Code'], regions)\n",
    "                num_of_country = len(country_new[row['Economy Code']])\n",
    "\n",
    "                if num_of_country == 1:\n",
    "                    single_name = country_new[row['Economy Code']]\n",
    "                    for common_name in single_name:\n",
    "                        region_name = common_name\n",
    "                        country_name = common_name\n",
    "                else:\n",
    "                    country_name, region_name = country_new[row['Economy Code']]\n",
    "\n",
    "                df_out_put.loc[index, ['Country']] = country_name\n",
    "                df_out_put.loc[index, ['ISO Code']] = row['Economy Code']\n",
    "                df_out_put.loc[index, ['Region']] = region_name\n",
    "\n",
    "                df_out_put.loc[index, ['Variable']] = remaining_attributes[1]\n",
    "                df_out_put.loc[index, ['Unit']] = remaining_attributes[2]\n",
    "                df_out_put.loc[index, ['Vehicle Type']] = remaining_attributes[0]\n",
    "                df_out_put.loc[index, ['Technology']] = \"All\"\n",
    "                df_out_put.loc[index, ['Fuel']] = \"All\"\n",
    "                df_out_put.loc[index, ['ID']] = remaining_attributes[4]\n",
    "\n",
    "                df_out_put.loc[index, ['Mode']] = upper_attributes[0]\n",
    "                df_out_put.loc[index, ['Source']] = upper_attributes[1]\n",
    "                df_out_put.loc[index, ['Service']] = upper_attributes[2]\n",
    "\n",
    "                col_length = len(df.columns)\n",
    "\n",
    "                for idx in range(col_length):\n",
    "                    if idx > 1:\n",
    "                        if not math.isnan(df.loc[index, column_list_names[idx]]):\n",
    "                            unit_value = df.loc[index, column_list_names[idx]]\n",
    "                            final_unit = unit_value / remaining_attributes[3]\n",
    "                            df_out_put.loc[index, column_list_names[idx]] = final_unit\n",
    "\n",
    "        return df_out_put\n",
    "\n",
    "        # Function that extract and process the input files and save the final data  \n",
    "    def process_input_data(self, workbook_file: str, master_file: str, regions_file: str, source_file: str):\n",
    "        # Steps followed for extracting and cleaning the dataset\n",
    "        #Step 1) Load both ATO workbook excel sheet and master dataset csv files into Dataframes\n",
    "        df = pd.read_excel(open(workbook_excel_file, 'rb'),sheet_name='TAS-FRA-007(2)')\n",
    "        \n",
    "\n",
    "        # Load the master data CSV file\n",
    "        master_df = pd.read_csv(master_csv_file)\n",
    "        master_column_names= list(master_df.columns.values)\n",
    "\n",
    "        #Step 2) Create a new dataframe using master dataset column names\n",
    "        df_out_put = pd.DataFrame(columns=master_column_names)\n",
    "\n",
    "        #Step 3) Separate the ATO workbook dataframe into two parts\n",
    "        #a) Upper part of the data frame containg 8 rows \n",
    "        df_upper = df.head(8)\n",
    "\n",
    "        #The function returns a list of \n",
    "        #[mode_value, source_value, service_value, unit_value, indicator_value, sheet_name]\n",
    "        upper_part_attributes = self.extract_upper_part_one(df_upper)\n",
    "\n",
    "        regions = self.populate_regions(regions_file)\n",
    "\n",
    "        rule_book = self.load_rule_book(source_file)\n",
    "\n",
    "        remaining_part_attributes = self.extract_upper_part_two(upper_part_attributes, rule_book)\n",
    "\n",
    "        # b) Lower part of the dataframe containing the remaining rows \n",
    "        # extract lower part of the dataframe\n",
    "        df_lower = df.iloc[13:66]\n",
    "\n",
    "        df_lower_new, updated_column_names = self.process_lower_part(df_lower)\n",
    "\n",
    "        master_df_output = self.update_master_data(df_out_put, df_lower_new, updated_column_names,\n",
    "                                        upper_part_attributes, remaining_part_attributes, regions)    \n",
    "\n",
    "        master_df_output.to_csv(\"Output_data \"+ upper_part_attributes[5] + \".csv\", index=False)\n",
    "\n",
    "# Name and path of input files\n",
    "workbook_excel_file = r\"C:/Users/magli/Desktop/item-internship/main/ATO Workbook (TRANSPORT ACTIVITY & SERVICES (TAS))2023.xlsx\"\n",
    "master_csv_file = r\"C:/Users/magli/Desktop/item-internship/code/sandra/Output_data TAS-FRA-007(2).csv\"\n",
    "regions_file = r\"regions.yaml\"\n",
    "source_file = r\"sources.yaml\"\n",
    "\n",
    "# Check if the Excel file exists\n",
    "if os.path.isfile(workbook_excel_file):\n",
    "    \n",
    "    # Process the input files and save output as csv file\n",
    "    atoWorkBook = AtoWorkbook()\n",
    "    atoWorkBook.process_input_data(workbook_excel_file, master_csv_file, regions_file, source_file)\n",
    "    print(\"File is found.\")\n",
    "else:\n",
    "    print(\"File is not found on the specified path!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
